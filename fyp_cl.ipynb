{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645616c-ac83-4ac9-8ac2-c3870266a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Initialize cameras\n",
    "cap1 = cv2.VideoCapture(0)  # Laptop webcam\n",
    "cap2 = cv2.VideoCapture(1)  # USB camera\n",
    "\n",
    "# Load object detection model\n",
    "# You'll need to download a pre-trained model and configure the paths accordingly\n",
    "model_path = 'path/to/frozen_inference_graph.pb'\n",
    "config_path = 'path/to/pipeline.config'\n",
    "detector = cv2.dnn.readNetFromTensorflow(model_path, config_path)\n",
    "\n",
    "# Initialize multi-object tracker\n",
    "tracker = cv2.MultiTracker_create()\n",
    "\n",
    "# Set up windows for dual-camera display\n",
    "cv2.namedWindow('Camera 1', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Camera 2', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Track objects across both cameras\n",
    "tracked_objects = deque()\n",
    "\n",
    "while True:\n",
    "    # Capture frames from both cameras\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if ret1 and ret2:\n",
    "        # Detect people in each frame\n",
    "        boxes1, scores1, classes1, nums1 = detector.forward(frame1)\n",
    "        boxes2, scores2, classes2, nums2 = detector.forward(frame2)\n",
    "\n",
    "        # Update and draw tracked objects\n",
    "        success, boxes1 = tracker.update(frame1)\n",
    "        success, boxes2 = tracker.update(frame2)\n",
    "        for i, (x, y, w, h) in enumerate(boxes1):\n",
    "            cv2.rectangle(frame1, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "        for i, (x, y, w, h) in enumerate(boxes2):\n",
    "            cv2.rectangle(frame2, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "\n",
    "        # Display FPS\n",
    "        fps1 = 1.0 / (time.time() - start_time1)\n",
    "        fps2 = 1.0 / (time.time() - start_time2)\n",
    "        cv2.putText(frame1, f'FPS: {fps1:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.putText(frame2, f'FPS: {fps2:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        # Display frames\n",
    "        cv2.imshow('Camera 1', frame1)\n",
    "        cv2.imshow('Camera 2', frame2)\n",
    "\n",
    "        # Update start times for FPS calculation\n",
    "        start_time1 = time.time()\n",
    "        start_time2 = time.time()\n",
    "\n",
    "    # Check for user input to exit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
